{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3759a8c1",
   "metadata": {},
   "source": [
    "# Merging GP regression sub-models using equivalent observations\n",
    "\n",
    "This notebook illustrates how to use the equivalent observation framework to train an ensemble of Gaussian process models and to make predictions with it.\n",
    "\n",
    "First, let's load some required packages and write some plotting functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "from gpflow.utilities import print_summary\n",
    "import guepard\n",
    "from guepard.utilities import get_gpr_submodels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The lines below are specific to the notebook format\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "from IPython.core.display import HTML, display\n",
    "display(HTML(\"<style>div.output_scroll { height: 150em; }</style>\"));\n",
    "\n",
    "# define a couple of plotting helper functions\n",
    "def plot_mean_conf(x, mean, var, ax, color='C0'):\n",
    "        ax.plot(x, mean, color, lw=2)\n",
    "        ax.fill_between(\n",
    "            x[:, 0],\n",
    "            mean[:, 0] - 1.96 * np.sqrt(var[:, 0]),\n",
    "            mean[:, 0] + 1.96 * np.sqrt(var[:, 0]),\n",
    "            color=color,\n",
    "            alpha=0.2,\n",
    "        )\n",
    "\n",
    "def plot_model(m, ax, x=np.linspace(0, 1, 101)[:, None], plot_data=True, color='C0'):\n",
    "    if plot_data:\n",
    "        X, Y = m.data\n",
    "        ax.plot(X, Y, \"kx\", mew=1.)\n",
    "    \n",
    "    mean, var = m.predict_f(x)\n",
    "    plot_mean_conf(x, mean, var, ax, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bedab",
   "metadata": {},
   "source": [
    "We now define a couple of helper functions, and generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135711a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_var = 0.01\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(10 * x[:, :1]) + 3. * x[:, :1]\n",
    "\n",
    "X = np.linspace(0, 1, 101)[:, None]\n",
    "Y = f(X) + np.sqrt(noise_var) * np.random.normal(size=X.shape)\n",
    "\n",
    "plt.plot(X, Y, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc28e934",
   "metadata": {},
   "source": [
    "We now split the dataset in three, and build a GPR model for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_split = 3\n",
    "\n",
    "Xl = np.array_split(X, num_split)  # list of num_split np.array\n",
    "Yl = np.array_split(Y, num_split)  \n",
    "\n",
    "kernel = gpflow.kernels.Matern32()\n",
    "\n",
    "# make submodels and plot them\n",
    "submodels = get_gpr_submodels(zip(Xl, Yl), kernel, noise_variance=noise_var) # list of num_split GPR models\n",
    "\n",
    "# M is a list of GPR models, let's plot them\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "x = np.linspace(0, 2, 101)[:, None]\n",
    "[plot_model(m, axes[i], x) for i, m in enumerate(submodels)];\n",
    "[axes[i].plot(X, Y, 'kx', mew=1., alpha=.1) for i, _ in enumerate(submodels)];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83303dd8",
   "metadata": {},
   "source": [
    "We can now aggregate the three sub-models using PAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_agg = guepard.EquivalentObsEnsemble(submodels)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "plot_model(m_agg, ax, plot_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776afb53",
   "metadata": {},
   "source": [
    "Guepard models inherit from `GPflow.GPmodels`, it is thus possible to interact with them like any other GPflow models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670db6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the value of one parameter\n",
    "m_agg.kernel.lengthscales.assign(0.3)\n",
    "\n",
    "# print the model parameter summary\n",
    "gpflow.utilities.print_summary(m_agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df339d",
   "metadata": {},
   "source": [
    "## Training the GPR sub-models\n",
    "\n",
    "Guepard models can be trained like any other GPflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_agg.training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = gpflow.optimizers.Scipy()\n",
    "opt_logs = opt.minimize(m_agg.training_loss, m_agg.trainable_variables, options=dict(maxiter=100))\n",
    "print_summary(m_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740165d6",
   "metadata": {},
   "source": [
    "## Comparison with a GPR model based on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd61d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a GPR model as baseline\n",
    "m_gpr = gpflow.models.GPR((X, Y), kernel, noise_variance=noise_var)\n",
    "opt_logs = opt.minimize(m_gpr.training_loss, m_gpr.trainable_variables, options=dict(maxiter=100))\n",
    "print_summary(m_gpr)\n",
    "\n",
    "# Check \"good\" match between aggregated model and gpr at training points\n",
    "mean_agg, var_agg = m_agg.predict_f(X)\n",
    "mean_gpr, var_gpr = m_gpr.predict_f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "plot_model(m_agg, axes[0], plot_data=False)\n",
    "plot_model(m_gpr, axes[0], plot_data=False, color='C1')\n",
    "\n",
    "axes[1].plot(x, mean_agg - mean_gpr, label=\"error in predicted mean\")\n",
    "axes[1].plot(x, np.sqrt(var_agg) - np.sqrt(var_gpr), label=\"error in predicted standard deviation\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f5509",
   "metadata": {},
   "source": [
    "On this simple example, predictions from PAPL are extremely close to the ground truth despite requiring to store and invert matrices that are 1/3rd of the size of a full model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde05dd5",
   "metadata": {},
   "source": [
    "## Sampling from the posterior\n",
    "\n",
    "Since Guepard models are classic GPflow models, we can use the build in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261a6b9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2, 101)[:, None]\n",
    "F = m_agg.predict_f_samples(x, 20).numpy()[:, :, 0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.plot(x, F.T, \"C0\", linewidth=.5);\n",
    "plot_model(m_agg, ax, x, plot_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779feaa0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af9c30ff",
   "metadata": {},
   "source": [
    "Alternatively, one can use the so-called Matheron trick to generate (approximate?) samples that are continuous functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from gpflux.layers.basis_functions.fourier_features import RandomFourierFeaturesCosine\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self, kernel, noise_variance=0., num_rff=10000):\n",
    "        self.features = RandomFourierFeaturesCosine(kernel, n_components=num_rff)\n",
    "        self.random_weight = np.random.normal(0, 1, (num_rff, 1))\n",
    "        self.noise_variance = noise_variance\n",
    "        \n",
    "    def signal(self, x):\n",
    "        signal = self.features(x) @ self.random_weight\n",
    "        return signal\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        noise = np.sqrt(self.noise_variance) * np.random.normal(0, 1, (x.shape[0], 1))\n",
    "        return  self.signal(x) + noise\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "\n",
    "for _ in range(10):\n",
    "    x = np.linspace(0, 2, 51)[:, None]\n",
    "    f = Sample(kernel)\n",
    "    E = Y - f(X) + np.sqrt(noise_var) * np.random.normal(size=Y.shape)\n",
    "    Es = np.array_split(E, num_split)\n",
    "\n",
    "    # build a list of submodels of the error\n",
    "    Me = get_gpr_submodels(zip(Xl, Es), kernel, noise_variance=noise_var)\n",
    "\n",
    "    # aggregate predictions\n",
    "    m_agg_error = guepard.EquivalentObsEnsemble(Me)\n",
    "    m, v = m_agg_error.predict_f(x)\n",
    "    ax.plot(x, f(x) + m, 'C2', lw=.5)\n",
    "\n",
    "plot_model(m_agg, ax, x, plot_data=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
