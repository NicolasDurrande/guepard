{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The equivalent observations method for GP model ensembles\n",
    "\n",
    "This notebook illustrates the concept of *equivalent observations*.\n",
    "\n",
    "First, let's load some required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4046865722.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/hf/nx4hh6mj3bsfyxc4p3splhxr0000gn/T/ipykernel_27801/4046865722.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    ormal as mvn\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "import guepard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gpflow.utilities import print_summary\n",
    "from guepard.gpr import get_gpr_submodels\n",
    "\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "# The lines below are specific to the notebook format\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 150em; }</style>\"));\n",
    "\n",
    "\n",
    "## Couple of helper functions for plotting\n",
    "\n",
    "# Plot the model\n",
    "def plot_mean_conf(x, mean, var, ax, color='C0', alpha=1.):\n",
    "        ax.plot(x, mean, color, lw=2, alpha=alpha)\n",
    "        ax.fill_between(\n",
    "            x[:, 0],\n",
    "            mean[:, 0] - 1.96 * np.sqrt(var[:, 0]),\n",
    "            mean[:, 0] + 1.96 * np.sqrt(var[:, 0]),\n",
    "            color=color,\n",
    "            alpha=alpha * 0.2,\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_model(m, ax, x=np.linspace(0, 1, 101)[:, None], plot_data=True, color='C0', alpha=1.):\n",
    "    if plot_data:\n",
    "        X, Y = m.data\n",
    "        ax.plot(X, Y, \"kx\", mew=1.)\n",
    "    \n",
    "    mean, var = m.predict_f(x)[:2]\n",
    "    plot_mean_conf(x, mean, var, ax, color, alpha)\n",
    "\n",
    "\n",
    "def plt_mvn(mu, Sigma, color='C0', linestyles='solid'):\n",
    "    x, y = np.meshgrid(np.linspace(-3.2, 2.5, 300),np.linspace(-2.5 ,8,300))\n",
    "    xy = np.column_stack([x.flat, y.flat])\n",
    "\n",
    "    # density values at the grid points\n",
    "    Z = mvn.pdf(xy, mu.flatten(), Sigma).reshape(x.shape)\n",
    "\n",
    "    # arbitrary contour levels\n",
    "    fig = plt.contour(x, y, Z, colors=color, levels=3, linestyles=linestyles, label='label')\n",
    "    mup, Sp = np.zeros((2, 1)), kernel.K(Xt).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a simple dataset and fit a GP model to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_var = 0.01\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(10 * x[:, :1]) + 3. * x[:, :1]\n",
    "\n",
    "X = np.linspace(0.3, 0.6, 30)[:, None]\n",
    "Y = f(X) + np.sqrt(noise_var) * np.random.normal(size=X.shape)\n",
    "\n",
    "# Define a GP model with GPflow\n",
    "kernel = gpflow.kernels.Matern32()\n",
    "m = gpflow.models.GPR((X, Y), kernel, noise_variance=noise_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $p$ prediction points $X^*$, the equivalent observation is defined as the vector $Y^*$ and the observation noise $\\varepsilon^* \\sim \\mathcal{N}(0, T)$ such that the posterior distribution of $f(X_t)$ given the equivalent observations matches exactly the posterior of $f(X_t)$ given the full dataset. In other words, $Y^*$ and $\\varepsilon^*$ are defined such that\n",
    "$$f(X_t)|f(X_t)+\\varepsilon^*=Y^* \\quad = \\quad f(X_t)|f(X)+\\varepsilon=Y$$ \n",
    "\n",
    "On our example, we can pick $X^* = [-0.15, 1.15]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.array([[-0.15, 1.15]]).T \n",
    "mup, Sp = np.zeros((2, 1)), kernel.K(Xt).numpy()\n",
    "\n",
    "jitter = 1e-8 * np.eye(2)\n",
    "\n",
    "# Compute the equivalent observations\n",
    "me1, Se1 = m.predict_f(Xt, full_cov=True)\n",
    "me1, Se1 = me1.numpy(), Se1.numpy()[0]\n",
    "Spl1 = Sp @ np.linalg.inv(Sp - Se1 + jitter) @ Sp - Sp\n",
    "Spl1 = np.linalg.inv(-np.linalg.inv(Sp) + np.linalg.inv(Se1) + jitter)   # This is T\n",
    "mpl1 = mup + Sp @ np.linalg.inv(Sp - Se1 + jitter) @ (me1 - mup)         # This is Y^*\n",
    "\n",
    "# posterior predictions given the equivalent observation\n",
    "x = np.linspace(-.5, 1.5, 101)[:, None]\n",
    "kx = kernel.K(x, Xt).numpy()\n",
    "kxx = kernel.K(x).numpy()\n",
    "mx = kx @ np.linalg.inv(Sp + Spl1) @ mpl1\n",
    "vx = kxx - kx @ np.linalg.inv(Sp + Spl1) @ kx.T\n",
    "vx = np.diag(vx)[:, None]\n",
    "\n",
    "# plot predictions\n",
    "fig, axes = plt.subplots(1, 1, figsize=(6, 3))\n",
    "x = np.linspace(-.5, 1.5, 101)[:, None]\n",
    "plt.plot(X, Y, 'kx', alpha=0.1)\n",
    "plot_model(m, axes, x)\n",
    "plot_mean_conf(x, mx, vx, axes, 'C1', alpha=.5)\n",
    "\n",
    "[axes.axvline(x, color='k', linestyle=\"dashed\", linewidth=.5, alpha=.5) for x in Xt]\n",
    "[plt.plot(x, y, \"C1o\", ms=5.) for x, y in zip(Xt, mpl1)]\n",
    "[plt.vlines(x, y-np.sqrt(c), y+np.sqrt(c) , \"C1\") for x, y, c in zip(Xt, mpl1, np.diag(Spl1))]\n",
    "axes.set_xticks(Xt.flatten().tolist())\n",
    "axes.set_yticks([])\n",
    "axes.set_xticklabels([\"$x_1$\", \"$x_2$\"])\n",
    "axes.set_ylabel(\"$y$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"plots/toy_implicit_obs.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one may choose to represent the equivalent observation as a likelihood function. With this point of view, the equivalent likelihood is function such that turns the prior distribution at test location into the posterior. It is thus given by the ratio posterior/prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "plt_mvn(mup, Sp, 'C3')\n",
    "plt_mvn(me1, Se1, 'C0')\n",
    "plt_mvn(mpl1, Spl1, 'C1')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "custom_lines = [Line2D([0], [0], color='C3', lw=1),\n",
    "                Line2D([0], [0], color='C0', lw=1),\n",
    "                Line2D([0], [0], color='C1', lw=1)]\n",
    "\n",
    "ax.legend(custom_lines, ['prior', 'posterior given data', 'equivalent likelihood'], loc=\"center left\", frameon=False)\n",
    "#ax.set_xticks([])\n",
    "#ax.set_yticks([])\n",
    "ax.set_xlabel(\"$f(x_1)$\")\n",
    "ax.set_ylabel(\"$f(x_2)$\")\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"plots/toy_implicit_lik.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to posterior predictions with a GPR ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a larger dataset that we split in three, and build a GPR model for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 101)[:, None]\n",
    "Y = f(X) + np.sqrt(noise_var) * np.random.normal(size=X.shape)\n",
    "\n",
    "num_split = 3\n",
    "\n",
    "Xl = np.array_split(X, num_split)  # list of num_split np.array\n",
    "Yl = np.array_split(Y, num_split)  \n",
    "\n",
    "kernel = gpflow.kernels.Matern32()\n",
    "\n",
    "# make submodels and aggregate them\n",
    "M = get_gpr_submodels(zip(Xl, Yl), kernel, noise_variance=noise_var) # list of num_split GPR models\n",
    "\n",
    "# plot submodel predictions\n",
    "x = np.linspace(-.5, 1.5, 101)[:, None]\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "for i, m in enumerate(M):    \n",
    "    ax = axes[i]\n",
    "    ax.plot(X, Y, 'kx', alpha=0.1)\n",
    "    plot_model(m, ax, x, alpha=1.)\n",
    "    ax.set_xlim([-.5, 1.5])\n",
    "    ax.axes.xaxis.set_ticks([])\n",
    "    ax.axes.yaxis.set_ticks([])\n",
    "    [ax.axvline(x, color='k', linestyle=\"dashed\", linewidth=.5, alpha=.5) for x in Xt]\n",
    "    ax.set_xticks(Xt.flatten().tolist())\n",
    "    ax.set_xticklabels([\"$x_1$\", \"$x_2$\"])\n",
    "    \n",
    "#[axes[i].plot(X, Y, 'kx', mew=1., alpha=.1) for i, _ in enumerate(M)];\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f\"plots/toy_submodels.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the prior, model 1 and the implitic observation at (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.array([[-0.15, 1.15]]).T \n",
    "mup, Sp = np.zeros((2, 1)), kernel.K(Xt).numpy()\n",
    "\n",
    "jitter = 1e-8 * np.eye(2)\n",
    "\n",
    "me0, Se0 = M[0].predict_f(Xt, full_cov=True)\n",
    "me0, Se0 = me0.numpy(), Se0.numpy()[0]\n",
    "Spl0 = Sp @ np.linalg.inv(Sp - Se0 + jitter) @ Sp - Sp\n",
    "Spl0 = np.linalg.inv(-np.linalg.inv(Sp) + np.linalg.inv(Se0) + jitter)\n",
    "mpl0 = mup + Sp @ np.linalg.inv(Sp - Se0 + jitter) @ (me0 - mup)\n",
    "\n",
    "me1, Se1 = M[1].predict_f(Xt, full_cov=True)\n",
    "me1, Se1 = me1.numpy(), Se1.numpy()[0]\n",
    "Spl1 = Sp @ np.linalg.inv(Sp - Se1 + jitter) @ Sp - Sp\n",
    "Spl1 = np.linalg.inv(-np.linalg.inv(Sp) + np.linalg.inv(Se1) + jitter)\n",
    "mpl1 = mup + Sp @ np.linalg.inv(Sp - Se1 + jitter) @ (me1 - mup)\n",
    "\n",
    "me2, Se2 = M[2].predict_f(Xt, full_cov=True)\n",
    "me2, Se2 = me2.numpy(), Se2.numpy()[0]\n",
    "Spl2 = Sp @ np.linalg.inv(Sp - Se2 + jitter) @ Sp - Sp\n",
    "Spl2 = np.linalg.inv(-np.linalg.inv(Sp) + np.linalg.inv(Se2) + jitter)\n",
    "mpl2 = mup + Sp @ np.linalg.inv(Sp - Se2 + jitter) @ (me2 - mup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "m_gpr = gpflow.models.GPR((X, Y), kernel, noise_variance=noise_var)\n",
    "m_agg = guepard.EquivalentObsEnsemble(M)\n",
    "\n",
    "mean_papl, var_papl = m_agg.predict_f(Xt, full_cov=True)\n",
    "mean_papl, var_papl = mean_papl.numpy(), var_papl.numpy()[0]\n",
    "mean_gpr, var_gpr = m_gpr.predict_f(Xt, full_cov=True)\n",
    "mean_gpr, var_gpr = mean_gpr.numpy(), var_gpr.numpy()[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "print(mean_gpr.shape, var_gpr.shape)\n",
    "plt_mvn(mup, Sp, 'C3')\n",
    "plt_mvn(mean_papl, var_papl, 'C0')\n",
    "plt_mvn(mean_gpr, var_gpr, 'k', linestyles='dotted')\n",
    "plt_mvn(mpl0, Spl0, 'C1', linestyles='dashed')\n",
    "plt_mvn(mpl1, Spl1, 'C1', linestyles='dashed')\n",
    "plt_mvn(mpl2, Spl2, 'C1', linestyles='dashed')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "custom_lines = [Line2D([0], [0], color='C3', lw=1),\n",
    "                Line2D([0], [0], color='C1', linestyle=\"dashed\", lw=1),\n",
    "                Line2D([0], [0], color='C0', lw=1),\n",
    "                Line2D([0], [0], color='k', linestyle=\"dotted\", lw=1)]\n",
    "\n",
    "ax.legend(custom_lines, ['prior', 'implicit likelihoods', 'approximate posterior', 'exact posterior'], loc=(0.02, .5), frameon=False)\n",
    "\n",
    "ax.set_xlabel(\"$f(x_1)$\")\n",
    "ax.set_ylabel(\"$f(x_2)$\")\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"plots/toy_approx_posterior.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a41565e6715b36c3e75045e67b09d906430734b554fe23fb80d9a0cfa9ccfc68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
